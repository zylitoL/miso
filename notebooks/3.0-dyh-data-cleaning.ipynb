{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "states = {\n",
    "    'AK': 'Alaska',\n",
    "    'AL': 'Alabama',\n",
    "    'AR': 'Arkansas',\n",
    "    'AZ': 'Arizona',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DC': 'District of Columbia',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'IA': 'Iowa',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MD': 'Maryland',\n",
    "    'ME': 'Maine',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MO': 'Missouri',\n",
    "    'MS': 'Mississippi',\n",
    "    'MT': 'Montana',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'NE': 'Nebraska',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NV': 'Nevada',\n",
    "    'NY': 'New York',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VA': 'Virginia',\n",
    "    'VT': 'Vermont',\n",
    "    'WA': 'Washington',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WV': 'West Virginia',\n",
    "    'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "abbreviations = {abbreviation: state for state, abbreviation in states.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `preprocess_state_sales.py`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2019 = pd.read_csv('../data/raw/ev_registrations_2019.csv')\n",
    "\n",
    "df2019 = df2019[:-1]\n",
    "\n",
    "df2019.index = df2019['State'].apply(lambda x: abbreviations[x])\n",
    "\n",
    "df2019['2019 EVs'] = df2019['EV Registrations 2019'].apply(int)\n",
    "df2019['2019 EVPercent'] = df2019['PercentTotalEV 2019'].apply(lambda x: float(x[:-1]) / 100)\n",
    "\n",
    "df2019 = df2019.drop(columns=['State', 'EV Registrations 2019', 'PercentTotalEV 2019'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df2021 = pd.read_csv('../data/raw/ev_registrations_2021.csv')\n",
    "\n",
    "df2021 = df2021[:-1]\n",
    "\n",
    "df2021.index = df2021['State'].apply(lambda x: abbreviations[x])\n",
    "\n",
    "df2021['2021 EVs'] = df2021['EVRegistrations 2021'].apply(lambda x: int(x.replace(',', '')))\n",
    "df2021['2021 EVPercent'] = df2021['PercentEVDistribution2021'].apply(lambda x: float(x[:-1]) / 100)\n",
    "\n",
    "df2021 = df2021.drop(columns=['State', 'EVRegistrations 2021', 'PercentEVDistribution2021'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sales = pd.merge(df2019, df2021, on='State')\n",
    "sales.to_csv('../data/interim/state_sales.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `preprocess_model_sales.py`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def process_model_rows(s):\n",
    "    # determine left and right \"boundaries\" of non-sales\n",
    "    left = -1\n",
    "    right = len(s)\n",
    "    for i in range(len(s)):  # normally we would use enumerate, but enumerating in reverse doesn't exist\n",
    "        x = s[i]\n",
    "        if x != '-':\n",
    "            left = i\n",
    "            break\n",
    "\n",
    "    for i in range(len(s) - 1, -1, -1):\n",
    "        x = s[i]\n",
    "        if x != '-':\n",
    "            right = i\n",
    "            break\n",
    "\n",
    "    # if a '-' entry is between the left and right cutoffs, we assume missing data\n",
    "    s = [\n",
    "        float(x.replace(',', '')) if x != '-'\n",
    "        else (0 if i < left or i > right else None)\n",
    "        for i, x in enumerate(s)\n",
    "    ]\n",
    "\n",
    "    return s\n",
    "\n",
    "def clean_hev(file_name):\n",
    "    vehicle_data = []\n",
    "\n",
    "    with open(file_name, 'r') as fin:\n",
    "        sale_data = csv.reader(fin)\n",
    "        *header, _ = next(sale_data) # skip header row, but keep information, except total\n",
    "\n",
    "        for row in sale_data:\n",
    "            vehicle, *data, _ = row # we need information about the vehicle and the yearly data, and can skip the total\n",
    "            vehicle_data.append([vehicle, *process_model_rows(data)])\n",
    "\n",
    "    df = pd.DataFrame(vehicle_data, columns=header)\n",
    "    df.index = df['Vehicle']\n",
    "    df['Type'] = 'HEV'\n",
    "    df = df.drop('Total')\n",
    "    df = df.drop(columns=['Vehicle'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_pev(file_name):\n",
    "    vehicle_data = []\n",
    "\n",
    "    with open(file_name, 'r') as fin:\n",
    "        sale_data = csv.reader(fin)\n",
    "        *header, _ = next(sale_data) # skip header row, but keep information, except total\n",
    "\n",
    "        for row in sale_data:\n",
    "            vehicle, ev_type, *data, _ = row # we need information about the vehicle and the yearly data, and can skip the total\n",
    "            vehicle_data.append([vehicle, ev_type, *process_model_rows(data)])\n",
    "\n",
    "    df = pd.DataFrame(vehicle_data, columns=header)\n",
    "    df.index = df['Vehicle']\n",
    "    df = df.drop('Total')\n",
    "    df = df.drop(columns=['Vehicle'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "hev_df = clean_hev('../data/raw/hev_sales.csv')\n",
    "pev_df = clean_pev('../data/raw/pev_sales.csv')\n",
    "\n",
    "model_df = pd.concat([hev_df, pev_df])\n",
    "model_df = model_df[['Type'] + [str(x) for x in range(1999, 2019 + 1)]]\n",
    "\n",
    "model_df.to_csv('../data/interim/model_sales.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `income_preprocess.py`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/median_income.csv')\n",
    "# Keep only median income columns\n",
    "temp_header = df.columns + ' ' + df.iloc[0]\n",
    "df.columns = temp_header\n",
    "\n",
    "seen = set()\n",
    "new_columns = []\n",
    "for column in df.columns:\n",
    "    if 'Standard error' in column: continue\n",
    "    year = column.split(\" \")[0]\n",
    "    if year in seen: continue\n",
    "    else:\n",
    "        new_columns.append(column)\n",
    "        seen.add(year)\n",
    "\n",
    "df = df[new_columns]\n",
    "\n",
    "# Reformat\n",
    "df = df.drop(df.index[0])\n",
    "df = df.drop(df.index[0])\n",
    "df = df.rename({'State State': 'State'}, axis=1)\n",
    "df.index = df['State']\n",
    "df = df.drop(columns=['State'])\n",
    "df.columns = df.columns[::-1]\n",
    "\n",
    "df.columns = [col.split(\" \")[0] for col in df.columns]\n",
    "df = df.applymap(lambda x: int(x.replace(\",\", \"\")))\n",
    "\n",
    "df.to_csv(\"../data/interim/income.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `populations.py`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/raw/population_p1.csv')\n",
    "df1 = df1.drop(df1.index[0])\n",
    "df1 = df1.rename({'Area Name': 'State'}, axis=1)\n",
    "df1.index = df1['State']\n",
    "df1 = df1.drop(columns=['State'])\n",
    "df1 = df1.loc[abbreviations.keys()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../data/raw/population_p2.csv')\n",
    "df2 = df2.drop(df2.index[0])\n",
    "df2 = df2.drop(columns=['Estimates Base (4/1/2010)'])\n",
    "df2 = df2.rename({'Area': 'State'}, axis=1)\n",
    "df2.index = df2['State']\n",
    "df2 = df2.drop(columns=['State'])\n",
    "df2 = df2.loc[abbreviations.keys()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "dfpop = pd.merge(df1, df2, on='State')\n",
    "dfpop = dfpop.applymap(lambda x: int(x.replace(\",\", \"\")))\n",
    "dfpop.to_csv('../data/interim/populations.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `state_year_preprocess.py`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def generate_records(file_name, data=None):\n",
    "    if not data:\n",
    "        data = []\n",
    "\n",
    "    with open(file_name) as fin:\n",
    "        reader = csv.DictReader(fin)\n",
    "        for data_dict in reader:\n",
    "            state = data_dict.pop('State')\n",
    "            if state == 'US': continue\n",
    "            if state not in states: state = abbreviations[state]\n",
    "            for year, value in data_dict.items():\n",
    "                data.append((state, int(year), float(value)))\n",
    "\n",
    "    return data\n",
    "\n",
    "field_names = ['Gasoline Price', 'Median Income', 'Population', 'Renewable Energy Use', 'Total Energy Use', 'Transportation Energy Use']\n",
    "file_names = ['../data/raw/gasoline_price.csv', '../data/interim/income.csv', '../data/interim/populations.csv', '../data/raw/renewable_energy_use.csv', '../data/raw/total_energy_use.csv', '../data/raw/transportation_energy_use.csv']\n",
    "\n",
    "dfs = []\n",
    "for field_name, file_name in zip(field_names, file_names):\n",
    "    records = generate_records(file_name)\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df.columns = ['State', 'Year', field_name]\n",
    "    dfs.append(df)\n",
    "\n",
    "from functools import reduce\n",
    "socioeconomic_df = reduce(lambda x, y: pd.merge(x, y, on=['State', 'Year']), dfs)\n",
    "socioeconomic_df = socioeconomic_df.set_index(['State', 'Year'])\n",
    "socioeconomic_df.to_csv('../data/processed/socioeconomic.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}